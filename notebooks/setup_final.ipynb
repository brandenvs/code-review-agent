{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Setup for Automating DfE Code Reviews\n",
    "\n",
    "> 3-Component agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Drops\n",
    "\n",
    "DROP TABLE tasks CASCADE;\n",
    "\n",
    "\n",
    "-- Creates\n",
    "\n",
    "CREATE TABLE tasks (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    task_name TEXT NOT NULL,\n",
    "    task_content TEXT NOT NULL,\n",
    "    task_instructions TEXT NOT NULL,\n",
    "    model_answer_1 TEXT NOT NULL,\n",
    "    model_answer_2 TEXT NOT NULL,\n",
    "    metadata JSONB\n",
    ");\n",
    "\n",
    "CREATE TABLE reviews (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    task_id INT NOT NULL,\n",
    "    task_name TEXT NOT NULL,\n",
    "    review_content TEXT NOT NULL,\n",
    "    submitted_content_1 TEXT NOT NULL,\n",
    "    submitted_content_2 TEXT NOT NULL,\n",
    "    metadata JSONB,\n",
    "    FOREIGN KEY (task_id) REFERENCES tasks (id) ON DELETE CASCADE\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Vectorisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT ai.create_vectorizer(   \n",
    "    'tasks'::regclass,\n",
    "    formatting => ai.formatting_python_template(\n",
    "        'Task Title: $task_name\\nTask Content: $chunk'\n",
    "    ),\n",
    "    embedding => ai.embedding_ollama('nomic-embed-text', 768),\n",
    "    chunking => ai.chunking_recursive_character_text_splitter('task_content', \n",
    "        chunk_size => 512, \n",
    "        chunk_overlap => 256\n",
    "    ),\n",
    "    destination => 'task_contents_embedding'\n",
    ");\n",
    "\n",
    "SELECT ai.create_vectorizer(   \n",
    "    'tasks'::regclass,\n",
    "    formatting => ai.formatting_python_template(\n",
    "        'Task Title: $task_name\\nTask Instructions: $chunk'\n",
    "    ),\n",
    "    embedding => ai.embedding_ollama('nomic-embed-text', 768),\n",
    "    chunking => ai.chunking_recursive_character_text_splitter('task_instructions', \n",
    "        chunk_size => 512, \n",
    "        chunk_overlap => 256\n",
    "    ),\n",
    "    destination => 'task_instructions_embedding'\n",
    ");\n",
    "\n",
    "SELECT ai.create_vectorizer(   \n",
    "    'tasks'::regclass,\n",
    "    formatting => ai.formatting_python_template('$chunk'),\n",
    "    embedding => ai.embedding_ollama('codellama:13b-instruct', 5120),\n",
    "    chunking => ai.chunking_recursive_character_text_splitter('model_answer_1'),\n",
    "    destination => 'task_model_answer_1_embedding'\n",
    ");\n",
    "\n",
    "SELECT ai.create_vectorizer(   \n",
    "    'tasks'::regclass,\n",
    "    formatting => ai.formatting_python_template('$chunk'),\n",
    "    embedding => ai.embedding_ollama('codellama:13b-instruct', 5120),\n",
    "    chunking => ai.chunking_recursive_character_text_splitter('model_answer_2'),\n",
    "    destination => 'task_model_answer_2_embedding'\n",
    ");\n",
    "\n",
    "-- Vectoriser status\n",
    "SELECT * FROM ai.vectorizer_status;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Vectorisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT ai.create_vectorizer(   \n",
    "    'reviews'::regclass,\n",
    "    formatting => ai.formatting_python_template('$chunk'),\n",
    "    embedding => ai.embedding_ollama('nomic-embed-text', 768),\n",
    "    chunking => ai.chunking_recursive_character_text_splitter('review_content', \n",
    "        chunk_size => 512, \n",
    "        chunk_overlap => 256\n",
    "    ),\n",
    "    destination => 'review_contents_embedding'\n",
    ");\n",
    "\n",
    "SELECT ai.create_vectorizer(   \n",
    "    'reviews'::regclass,\n",
    "    formatting => ai.formatting_python_template('$chunk'),\n",
    "    embedding => ai.embedding_ollama('codellama:13b-instruct', 5120),\n",
    "    chunking => ai.chunking_recursive_character_text_splitter('submitted_content_1'),\n",
    "    destination => 'submitted_content_1_embedding'\n",
    ");\n",
    "\n",
    "SELECT ai.create_vectorizer(   \n",
    "    'reviews'::regclass,\n",
    "    formatting => ai.formatting_python_template('$chunk'),\n",
    "    embedding => ai.embedding_ollama('codellama:13b-instruct', 5120),\n",
    "    chunking => ai.chunking_recursive_character_text_splitter('submitted_content_2'),\n",
    "    destination => 'submitted_content_2_embedding'\n",
    ");\n",
    "\n",
    "SELECT * FROM ai.vectorizer_status;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Vectoriser execute\n",
    "SELECT ai.execute_vectorizer(00);\n",
    "\n",
    "-- Vectoriser status\n",
    "select * from ai.vectorizer_status;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic - General Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION general_response(query_text TEXT)\n",
    "RETURNS TEXT AS $$\n",
    "DECLARE\n",
    "    context_chunks TEXT;\n",
    "    response TEXT;\n",
    "BEGIN\n",
    "    WITH relevant_info AS (\n",
    "    (SELECT \n",
    "        'Task Contexts' AS source,\n",
    "        t1.task_name,\n",
    "        t1.chunk, t2.chunk\n",
    "        FROM task_contents_embedding t1\n",
    "        INNER JOIN task_instructions_embedding t2\n",
    "        ON t1.task_name = t2.task_name\n",
    "        ORDER BY embedding <=> ai.ollama_embed('nomic-embed-text', task_title)\n",
    "        LIMIT 1\n",
    "        )\n",
    "        UNION ALL\n",
    "        (SELECT\n",
    "        'Model Answer Contexts' AS source,\n",
    "        t1.task_name,\n",
    "        t1.chunk, t2.chunk\n",
    "        FROM task_model_answer_1_embedding t1\n",
    "        INNER JOIN task_model_answer_2_embedding t2\n",
    "        ON t1.task_name = t2.task_name\n",
    "        ORDER BY embedding <=> ai.ollama_embed('codellama:13b-instruct', query_code_1)\n",
    "        LIMIT 1\n",
    "        )\n",
    "        UNION ALL\n",
    "        (SELECT \n",
    "        'Review Context' AS source,\n",
    "        chunk\n",
    "        FROM review_contents_embedding\n",
    "        ORDER BY embedding <=> ai.ollama_embed('nomic-embed-text', task_title)\n",
    "        LIMIT 1\n",
    "        )\n",
    "        UNION ALL\n",
    "        (SELECT\n",
    "        'Submission Answer Contexts' AS source,\n",
    "        t1.task_name,\n",
    "        t1.chunk, t2.chunk\n",
    "        FROM submitted_content_1_embedding t1\n",
    "        INNER JOIN submitted_content_2_embedding t2\n",
    "        ON t1.task_name = t2.task_name\n",
    "        ORDER BY embedding <=> ai.ollama_embed('codellama:13b-instruct', query_code_1 || E'\\n\\n' || query_code_2)\n",
    "        LIMIT 1\n",
    "        )\n",
    "    )\n",
    "    SELECT string_agg(\n",
    "        source || E':\\n' || chunk, \n",
    "        E'\\n\\n'\n",
    "    ) \n",
    "    INTO context_chunks\n",
    "    FROM relevant_info;\n",
    "\n",
    "    SELECT ai.ollama_chat_complete(\n",
    "        'llama3',\n",
    "        jsonb_build_array(\n",
    "        jsonb_build_object('role', 'system', 'content', 'You are a helpful code reviewer. Provide accurate and concise answers based on the given context.'),\n",
    "        jsonb_build_object(\n",
    "            'role', 'user',\n",
    "            'content', query_text || E'\\n\\nUse the following context to respond:\\n' || context_chunks\n",
    "        )\n",
    "        )\n",
    "    )->'message'->>'content' INTO response;\n",
    "\n",
    "    RETURN response;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex - General Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION general_response(query_text TEXT)\n",
    "RETURNS TEXT AS $$\n",
    "DECLARE\n",
    "    context_chunks TEXT;\n",
    "    response TEXT;\n",
    "BEGIN\n",
    "    WITH relevant_info AS (\n",
    "        (SELECT \n",
    "            'Task Contexts' AS source,\n",
    "            t1.task_name,\n",
    "            t1.chunk || E'\\n' || t2.chunk AS chunk\n",
    "            FROM task_contents_embedding t1\n",
    "            INNER JOIN task_instructions_embedding t2\n",
    "            ON t1.task_name = t2.task_name\n",
    "            ORDER BY t1.embedding <=> ai.ollama_embed('nomic-embed-text', query_text)\n",
    "            LIMIT 1\n",
    "        )\n",
    "        UNION ALL\n",
    "        (SELECT\n",
    "            'Model Answer Contexts' AS source,\n",
    "            t1.task_name,\n",
    "            t1.chunk || E'\\n' || t2.chunk AS chunk\n",
    "            FROM task_model_answer_1_embedding t1\n",
    "            INNER JOIN task_model_answer_2_embedding t2\n",
    "            ON t1.task_name = t2.task_name\n",
    "            ORDER BY t1.embedding <=> ai.ollama_embed('codellama:13b-instruct', query_text)\n",
    "        )\n",
    "        UNION ALL\n",
    "        (SELECT \n",
    "            'Review Context' AS source,\n",
    "            '' AS task_name,\n",
    "            chunk\n",
    "            FROM review_contents_embedding\n",
    "            ORDER BY embedding <=> ai.ollama_embed('nomic-embed-text', query_text)\n",
    "        )\n",
    "        UNION ALL\n",
    "        (SELECT\n",
    "            'Submission Answer Contexts' AS source,\n",
    "            t1.task_name,\n",
    "            t1.chunk || E'\\n' || t2.chunk AS chunk\n",
    "            FROM submitted_content_1_embedding t1\n",
    "            INNER JOIN submitted_content_2_embedding t2\n",
    "            ON t1.task_name = t2.task_name\n",
    "            ORDER BY t1.embedding <=> ai.ollama_embed('codellama:13b-instruct', query_text)\n",
    "        )\n",
    "    )\n",
    "    SELECT string_agg(\n",
    "        source || E': ' || task_name || E'\\n' || chunk, \n",
    "        E'\\n\\n'\n",
    "    ) \n",
    "    INTO context_chunks\n",
    "    FROM relevant_info;\n",
    "\n",
    "    SELECT ai.ollama_chat_complete(\n",
    "        'llama3',\n",
    "        jsonb_build_array(\n",
    "            jsonb_build_object('role', 'system', 'content', 'You are a helpful code reviewer. Provide accurate and concise answers based on the given context.'),\n",
    "            jsonb_build_object(\n",
    "                'role', 'user',\n",
    "                'content', query_text || E'\\n\\nUse the following context to respond:\\n' || context_chunks\n",
    "            )\n",
    "        )\n",
    "    )->'message'->>'content' INTO response;\n",
    "\n",
    "    RETURN response;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\n",
    "\n",
    "-- Test query for general_response function\n",
    "SELECT general_response(\n",
    "    'Provide a summary of all tasks and their objectives as outlined in the task instructions. \n",
    "    Additionally, identify any associated reviews and summarize their content. \n",
    "    Ensure the summary is structured as follows:\n",
    "    \n",
    "    - Task Name: [Task Name]\n",
    "      Objective: [Extracted from Task Instructions]\n",
    "      Reviews:\n",
    "        1. [First Review Summary]\n",
    "        2. [Second Review Summary]\n",
    "    \n",
    "    Include any model answers for each task as supplementary information.'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION general_response(query_text TEXT)\n",
    "RETURNS TEXT AS $$\n",
    "DECLARE\n",
    "    context_chunks TEXT;\n",
    "    response TEXT;\n",
    "BEGIN\n",
    "    WITH relevant_info AS (\n",
    "        -- Task Context\n",
    "        (SELECT \n",
    "            'Task Contexts' AS source,\n",
    "            t1.task_name,\n",
    "            t1.chunk || E'\\n' || t2.chunk AS chunk\n",
    "        FROM task_contents_embedding t1\n",
    "        INNER JOIN task_instructions_embedding t2\n",
    "        ON t1.task_name = t2.task_name\n",
    "        ORDER BY t1.embedding <=> ai.ollama_embed('nomic-embed-text', query_text)\n",
    "        )\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Model Answer Context\n",
    "        (SELECT\n",
    "            'Model Answer Contexts' AS source,\n",
    "            t1.task_name,\n",
    "            t1.chunk || E'\\n' || t2.chunk AS chunk\n",
    "        FROM task_model_answer_1_embedding t1\n",
    "        INNER JOIN task_model_answer_2_embedding t2\n",
    "        ON t1.task_name = t2.task_name\n",
    "        ORDER BY t1.embedding <=> ai.ollama_embed('codellama:13b-instruct', query_text)\n",
    "        )\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Review Context\n",
    "        (SELECT \n",
    "            'Review Context' AS source,\n",
    "            '' AS task_name,\n",
    "            chunk\n",
    "        FROM review_contents_embedding\n",
    "        ORDER BY embedding <=> ai.ollama_embed('nomic-embed-text', query_text)\n",
    "        )\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Submission Answer Context\n",
    "        (SELECT\n",
    "            'Submission Answer Contexts' AS source,\n",
    "            t1.task_name,\n",
    "            t1.chunk || E'\\n' || t2.chunk AS chunk\n",
    "        FROM submitted_content_1_embedding t1\n",
    "        INNER JOIN submitted_content_2_embedding t2\n",
    "        ON t1.task_name = t2.task_name\n",
    "        ORDER BY t1.embedding <=> ai.ollama_embed('codellama:13b-instruct', query_text)\n",
    "        )\n",
    "    )\n",
    "    SELECT string_agg(\n",
    "        source || E': ' || COALESCE(task_name, 'N/A') || E'\\n' || chunk,\n",
    "        E'\\n\\n'\n",
    "    ) \n",
    "    INTO context_chunks\n",
    "    FROM relevant_info;\n",
    "\n",
    "    -- Construct the final response using AI model\n",
    "    SELECT ai.ollama_chat_complete(\n",
    "        'llama3',\n",
    "        jsonb_build_array(\n",
    "            jsonb_build_object(\n",
    "                'role', 'system', \n",
    "                'content', 'You are a helpful assistant providing structured responses based on the given context.'\n",
    "            ),\n",
    "            jsonb_build_object(\n",
    "                'role', 'user',\n",
    "                'content', query_text || E'\\n\\nUse the following context to respond:\\n' || COALESCE(context_chunks, 'No relevant context found.')\n",
    "            )\n",
    "        )\n",
    "    )->'message'->>'content' \n",
    "    INTO response;\n",
    "\n",
    "    RETURN response;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\n",
    "\n",
    "-- Test query for general_response function\n",
    "SELECT general_response(\n",
    "    'Provide a summary of all tasks and their objectives as outlined in the task instructions. \n",
    "    Additionally, identify any associated reviews and summarize their content. \n",
    "    Ensure the summary is structured as follows:\n",
    "    \n",
    "    - Task Name: [Task Name]\n",
    "      Objective: [Extracted from Task Instructions]\n",
    "      Reviews:\n",
    "        1. [First Review Summary]\n",
    "        2. [Second Review Summary]\n",
    "    \n",
    "    Include any model answers for each task as supplementary information.'\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION general_response(query_text TEXT)\n",
    "RETURNS TEXT AS $$\n",
    "DECLARE\n",
    "    context_chunks TEXT;\n",
    "    response TEXT;\n",
    "BEGIN\n",
    "    WITH relevant_info AS (\n",
    "        -- Task Contexts with clear task separation\n",
    "        (SELECT \n",
    "            t1.task_name,\n",
    "            '===== Task: ' || t1.task_name || ' =====' || E'\\n'\n",
    "            || 'Task Context:\\n' || t1.chunk || E'\\n'\n",
    "            || 'Instructions:\\n' || t2.chunk AS chunk\n",
    "        FROM task_contents_embedding t1\n",
    "        INNER JOIN task_instructions_embedding t2\n",
    "        ON t1.task_name = t2.task_name\n",
    "        ORDER BY t1.embedding <=> ai.ollama_embed('nomic-embed-text', query_text)\n",
    "        LIMIT 3)\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Model Answer Contexts\n",
    "        (SELECT\n",
    "            t1.task_name,\n",
    "            '===== Task: ' || t1.task_name || ' =====' || E'\\n'\n",
    "            || 'Model Answer 1:\\n' || t1.chunk || E'\\n'\n",
    "            || 'Model Answer 2:\\n' || t2.chunk AS chunk\n",
    "        FROM task_model_answer_1_embedding t1\n",
    "        INNER JOIN task_model_answer_2_embedding t2\n",
    "        ON t1.task_name = t2.task_name\n",
    "        ORDER BY t1.embedding <=> ai.ollama_embed('codellama:13b-instruct', query_text)\n",
    "        LIMIT 2)\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Review Contexts\n",
    "        (SELECT \n",
    "            '' AS task_name,\n",
    "            '===== Review Context =====' || E'\\n' || chunk AS chunk\n",
    "        FROM review_contents_embedding\n",
    "        ORDER BY embedding <=> ai.ollama_embed('nomic-embed-text', query_text)\n",
    "        LIMIT 5)\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        -- Submission Answer Contexts\n",
    "        (SELECT\n",
    "            t1.task_name,\n",
    "            '===== Task: ' || t1.task_name || ' =====' || E'\\n'\n",
    "            || 'Submission Answer 1:\\n' || t1.chunk || E'\\n'\n",
    "            || 'Submission Answer 2:\\n' || t2.chunk AS chunk\n",
    "        FROM submitted_content_1_embedding t1\n",
    "        INNER JOIN submitted_content_2_embedding t2\n",
    "        ON t1.task_name = t2.task_name\n",
    "        ORDER BY t1.embedding <=> ai.ollama_embed('codellama:13b-instruct', query_text)\n",
    "        LIMIT 2)\n",
    "    )\n",
    "    SELECT string_agg(chunk, E'\\n\\n') \n",
    "    INTO context_chunks\n",
    "    FROM relevant_info;\n",
    "\n",
    "    -- Generate the response using AI model\n",
    "    SELECT ai.ollama_chat_complete(\n",
    "        'llama3',\n",
    "        jsonb_build_array(\n",
    "            jsonb_build_object(\n",
    "                'role', 'system',\n",
    "                'content', 'You are a helpful assistant. Answer the query using the structured context provided, clearly separated by task.'\n",
    "            ),\n",
    "            jsonb_build_object(\n",
    "                'role', 'user',\n",
    "                'content', query_text || E'\\n\\nStructured Context:\\n' || COALESCE(context_chunks, 'No relevant context found.')\n",
    "            )\n",
    "        )\n",
    "    )->'message'->>'content' \n",
    "    INTO response;\n",
    "\n",
    "    RETURN response;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\n",
    "-- Test query for general_response function\n",
    "SELECT general_response(\n",
    "    'Provide a summary of all tasks and their objectives as outlined in the task instructions. \n",
    "    Additionally, identify any associated reviews and summarize their content. \n",
    "    Ensure the summary is structured as follows:\n",
    "    \n",
    "    - Task Name: [Task Name]\n",
    "      Objective: [Extracted from Task Instructions]\n",
    "      Reviews:\n",
    "        1. [First Review Summary]\n",
    "        2. [Second Review Summary]\n",
    "    \n",
    "    Include any model answers for each task as supplementary information.'\n",
    ");\n",
    "\n",
    "SELECT general_response(\n",
    "    'Summarize the objectives of each task from the instructions, and provide any associated reviews. \n",
    "    For each task, also list model answers and submissions as available. Ensure the tasks are clearly separated in your response.'\n",
    ");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION generate_review(query_code_1 TEXT, query_code_2 TEXT, task_title TEXT, file_name TEXT)\n",
    "RETURNS TEXT AS $$\n",
    "DECLARE\n",
    "  context_chunks TEXT;\n",
    "  response TEXT;\n",
    "BEGIN\n",
    "  WITH relevant_info AS (\n",
    "    (SELECT \n",
    "      'Task Contexts' AS source,\n",
    "      t1.task_name,\n",
    "      t1.chunk, t2.chunk\n",
    "      FROM task_contents_embedding t1\n",
    "      INNER JOIN task_instructions_embedding t2\n",
    "      ON t1.task_name = t2.task_name\n",
    "      ORDER BY embedding <=> ai.ollama_embed('nomic-embed-text', task_title)\n",
    "      LIMIT 1\n",
    "    )\n",
    "    UNION ALL\n",
    "    (SELECT\n",
    "      'Model Answer Contexts' AS source,\n",
    "      t1.task_name,\n",
    "      t1.chunk, t2.chunk\n",
    "      FROM task_model_answer_1_embedding t1\n",
    "      INNER JOIN task_model_answer_2_embedding t2\n",
    "      ON t1.task_name = t2.task_name\n",
    "      ORDER BY embedding <=> ai.ollama_embed('codellama:13b-instruct', query_code_1)\n",
    "      LIMIT 1\n",
    "    )\n",
    "    UNION ALL\n",
    "    (SELECT \n",
    "      'Review Context' AS source,\n",
    "      chunk\n",
    "      FROM review_contents_embedding\n",
    "      ORDER BY embedding <=> ai.ollama_embed('nomic-embed-text', task_title)\n",
    "      LIMIT 1\n",
    "    )\n",
    "    UNION ALL\n",
    "    (SELECT\n",
    "      'Submission Answer Contexts' AS source,\n",
    "      t1.task_name,\n",
    "      t1.chunk, t2.chunk\n",
    "      FROM submitted_content_1_embedding t1\n",
    "      INNER JOIN submitted_content_2_embedding t2\n",
    "      ON t1.task_name = t2.task_name\n",
    "      ORDER BY embedding <=> ai.ollama_embed('codellama:13b-instruct', query_code_1 || E'\\n\\n' || query_code_2)\n",
    "      LIMIT 1\n",
    "    )\n",
    "  )\n",
    "  SELECT string_agg(\n",
    "    source || E':\\n' || chunk, \n",
    "    E'\\n\\n'\n",
    "  ) \n",
    "  INTO context_chunks\n",
    "  FROM relevant_info;\n",
    "\n",
    "  SELECT ai.ollama_chat_complete(\n",
    "    'llama3',\n",
    "    jsonb_build_array(\n",
    "      jsonb_build_object(\n",
    "        'role', 'system', \n",
    "        'content', 'You are an expert code reviewer. Your task is to review the given code (query_text) and ensure it matches the task instructions. Provide a detailed review, highlighting strengths, areas for improvement, and any discrepancies between the code and the task requirements.'\n",
    "      ),\n",
    "      jsonb_build_object(\n",
    "        'role', 'user',\n",
    "        'content', 'Task Name: ' || task_title || E'\\n\\n' ||\n",
    "        'File name:\\n' || file_name || E'\\n\\n' ||\n",
    "        'Code to review:\\n' || query_text_1 || query_text_2 || E'\\n\\n' ||\n",
    "        'Use the following context for your review:\\n' || context_chunks || E'\\n\\n' ||\n",
    "        'Please provide a comprehensive code review, focusing on how well the code matches the task instructions. Include specific suggestions for improvement if necessary.'\n",
    "      )\n",
    "    )\n",
    "  )->'message'->>'content' INTO response;\n",
    "\n",
    "  RETURN response;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
